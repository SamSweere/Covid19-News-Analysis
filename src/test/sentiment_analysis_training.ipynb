{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Spacy Transformers Demo",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "416f4e2b196d43d995c7413aca85b8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44f260c98df848389a6ac8a10de52dad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f28b0309f28d4349af4ea7c369b19c1b",
              "IPY_MODEL_06099dfce5a346a1bc163e76be4e8bc3"
            ]
          }
        },
        "44f260c98df848389a6ac8a10de52dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f28b0309f28d4349af4ea7c369b19c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8dd7da4ae25045d199f869d6740e1e48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0139ef592a3a462fa39074b431c391fd"
          }
        },
        "06099dfce5a346a1bc163e76be4e8bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4cdf6eac13146a49b7d737e5046a919",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 101/? [01:50&lt;00:00,  1.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c237e23650304025b83121c2b2fc87b3"
          }
        },
        "8dd7da4ae25045d199f869d6740e1e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0139ef592a3a462fa39074b431c391fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4cdf6eac13146a49b7d737e5046a919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c237e23650304025b83121c2b2fc87b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "157a5af224c84b7bb328cc49f666ecd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50b461ef5a8048fdba68f433daf1cfd8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b4a3cd5a3f842a98f9f85ebf78f25e6",
              "IPY_MODEL_5e35b807e5364f42a8cb910a399aad9e"
            ]
          }
        },
        "50b461ef5a8048fdba68f433daf1cfd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b4a3cd5a3f842a98f9f85ebf78f25e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e98e9bfb6cb043518b5427816a3bd1b8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 477016,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 477016,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c52339f287ac47818f72d17514a939b1"
          }
        },
        "5e35b807e5364f42a8cb910a399aad9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8175ecd95b8b49a990369e3dbccd84a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 477016/477016 [01:54&lt;00:00, 3971.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c1992b313b444ddaa16a91117227783"
          }
        },
        "e98e9bfb6cb043518b5427816a3bd1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c52339f287ac47818f72d17514a939b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8175ecd95b8b49a990369e3dbccd84a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c1992b313b444ddaa16a91117227783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e502a7e6dd440d294611da709109594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e2dc3c58d614254be15e45a56b7091b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_341753933cea4c59a05d65dc799f53d6",
              "IPY_MODEL_06cbc972d96c413c847ce6743a17741e"
            ]
          }
        },
        "1e2dc3c58d614254be15e45a56b7091b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "341753933cea4c59a05d65dc799f53d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1e9de5345a84abbb4101f7d242c0868",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46522f60f3c54626a9d97f00e6e8f252"
          }
        },
        "06cbc972d96c413c847ce6743a17741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e400271445b3423fb5c6e76d1ebc86d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [01:39&lt;00:00,  1.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_394bc071560e4cde8a6696d05f1d7231"
          }
        },
        "e1e9de5345a84abbb4101f7d242c0868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46522f60f3c54626a9d97f00e6e8f252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e400271445b3423fb5c6e76d1ebc86d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "394bc071560e4cde8a6696d05f1d7231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "474c8ae3da504fd8b21835268c0e9aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bbce3e295b64e45ac24a9eeb6024017",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d24fa346469421d831379883e01b878",
              "IPY_MODEL_b23424b0be824b53b4405f62f67d5f80"
            ]
          }
        },
        "3bbce3e295b64e45ac24a9eeb6024017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d24fa346469421d831379883e01b878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6985545b7e7b42efab6bb4241b13ddaa",
            "_dom_classes": [],
            "description": " 22%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 477016,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 104611,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1462da6392c94aed9153e037c2eec5df"
          }
        },
        "b23424b0be824b53b4405f62f67d5f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13aecc590050491e9758216d348bba86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104611/477016 [00:25&lt;01:45, 3546.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c15147003b2e41148f0a13d70b00ac80"
          }
        },
        "6985545b7e7b42efab6bb4241b13ddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1462da6392c94aed9153e037c2eec5df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13aecc590050491e9758216d348bba86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c15147003b2e41148f0a13d70b00ac80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsWgat3MGCd",
        "colab_type": "text"
      },
      "source": [
        "# Spacy PyTorch Transformers Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne31B42Q9tu0",
        "colab_type": "code",
        "outputId": "b25a19d2-3f33-42bf-a672-7194c3c57a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May  5 21:01:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKvZ1y3d3Ak8",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lG3ReZc9ESyVPsstjuu5ek73u6vVsi3X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJqDMGd8MROv",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://d33wubrfki0l68.cloudfront.net/d04566d0f6671ae94fdae6fa3f767f5a6553d335/c50f0/blog/img/spacy-pytorch-transformers.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzJ2Uy6TTt58",
        "colab_type": "text"
      },
      "source": [
        "# Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BhrT_sQMiH0",
        "colab_type": "text"
      },
      "source": [
        "Setting up the environment in Colab to run various experiments, note the cuda version of spacy-pytorch-transformers is being downloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHnQiSqRZFLg",
        "colab_type": "code",
        "outputId": "bcb10fd9-6f60-41e5-aa47-5b96a48a68a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install gputil\n",
        "!pip install torch #==1.1.0\n",
        "!pip install spacy-pytorch-transformers[cuda100] #==0.2.0\n",
        "!pip install --upgrade spacy\n",
        "!pip install --upgrade spacy-pytorch-transformers\n",
        "\n",
        "# !python -m spacy download en_pytt_bertbaseuncased_lg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.3)\n",
            "Requirement already satisfied: spacy-pytorch-transformers[cuda100] in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (0.0.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (1.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (1.0.2)\n",
            "Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (2.1.9)\n",
            "Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (5.7)\n",
            "Requirement already satisfied: pytorch-transformers<1.1.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (1.0.0)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (0.6)\n",
            "Requirement already satisfied: cupy-cuda100>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (8.0.0b2)\n",
            "Requirement already satisfied: thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (0.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->spacy-pytorch-transformers[cuda100]) (1.18.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.6.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.23.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (1.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]) (0.1.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (4.38.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (0.1.86)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (1.13.1)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]) (0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (1.16.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.1->boto3->pytorch-transformers<1.1.0,>=1.0.0->spacy-pytorch-transformers[cuda100]) (1.12.0)\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/2e/ac00f5c9d01e66cc6ab75eb2a460c9b0dc21ad99a12f810c86a58309e63c/spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.3)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Collecting thinc==7.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ed/8e4559f1090fb05c0fa982a8a2caaa315967e7b460652be479d13fd1c813/thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "\u001b[31mERROR: spacy-pytorch-transformers 0.2.0 has requirement spacy<2.2.0,>=2.1.7, but you'll have spacy 2.2.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: preshed, blis, thinc, spacy\n",
            "  Found existing installation: preshed 2.0.1\n",
            "    Uninstalling preshed-2.0.1:\n",
            "      Successfully uninstalled preshed-2.0.1\n",
            "  Found existing installation: blis 0.2.4\n",
            "    Uninstalling blis-0.2.4:\n",
            "      Successfully uninstalled blis-0.2.4\n",
            "  Found existing installation: thinc 7.0.8\n",
            "    Uninstalling thinc-7.0.8:\n",
            "      Successfully uninstalled thinc-7.0.8\n",
            "  Found existing installation: spacy 2.1.9\n",
            "    Uninstalling spacy-2.1.9:\n",
            "      Successfully uninstalled spacy-2.1.9\n",
            "Successfully installed blis-0.4.1 preshed-3.0.2 spacy-2.2.4 thinc-7.4.0\n",
            "Collecting spacy-pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (0.6)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (1.1.0)\n",
            "Collecting pytorch-transformers<1.3.0,>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (0.0.2)\n",
            "Requirement already satisfied, skipping upgrade: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (5.7)\n",
            "Collecting spacy<2.2.0,>=2.1.7\n",
            "  Using cached https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->spacy-pytorch-transformers) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.1.86)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (0.6.0)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Using cached https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (0.9.6)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Using cached https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=9e304339dda94e5a2727c3c7c359e340a3ce7d88c73a19506d9f5ecd6816452b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, pytorch-transformers, preshed, blis, thinc, spacy, spacy-pytorch-transformers\n",
            "  Found existing installation: pytorch-transformers 1.0.0\n",
            "    Uninstalling pytorch-transformers-1.0.0:\n",
            "      Successfully uninstalled pytorch-transformers-1.0.0\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: spacy-pytorch-transformers 0.2.0\n",
            "    Uninstalling spacy-pytorch-transformers-0.2.0:\n",
            "      Successfully uninstalled spacy-pytorch-transformers-0.2.0\n",
            "Successfully installed blis-0.2.4 preshed-2.0.1 pytorch-transformers-1.2.0 sacremoses-0.0.43 spacy-2.1.9 spacy-pytorch-transformers-0.4.0 thinc-7.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvGebzW-xtlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_pytt_xlnetbasecased_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j0oHvNgMwms",
        "colab_type": "text"
      },
      "source": [
        "You will need to **restart runtime after these installs** to reinstatiate the environment/directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt50zr1JOe5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import GPUtil\n",
        "import torch\n",
        "import numpy\n",
        "from numpy.testing import assert_almost_equal\n",
        "from scipy.spatial import distance\n",
        "import cupy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dh86HU_Op-_",
        "colab_type": "text"
      },
      "source": [
        "Checks whether GPU is available, switches to cuda if it is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MfBlpUiKVKt",
        "colab_type": "code",
        "outputId": "c6173b82-23f6-472c-929a-323de5d5293c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    print(\"Using GPU!\")\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "    print(\"GPU Usage\")\n",
        "    GPUtil.showUtilization()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU!\n",
            "GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  0% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUzXv4DfTyml",
        "colab_type": "text"
      },
      "source": [
        "# XL-Net & BERT Models Explained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoy7qKqvTsgC",
        "colab_type": "text"
      },
      "source": [
        "2018 was a breakthrough year for NLP with the release of BERT , most of them centered around language modeling.  In case you’re not familiar, language modeling is a fancy word for the task of predicting the next word in a sentence given all previous words. This seemingly simple task has a surprising amount of depth and the true potential of language modeling started to be unlocked by methods using it as a pretraining method.\n",
        "\n",
        "The forerunners in this trend were ULMFiT and ELMo, both of which used LSTM-based language models. The basic idea of these methods was to train a language model on massive amounts of unlabeled data and then use the internal representations of the language model on subsequent tasks with smaller datasets such as question answering and text classification. This was a form of transfer learning, where a larger dataset was used to bootstrap a model that could then perform better on other tasks. The reason this worked so well was that language models captured general aspects of the input text that were almost universally useful. Indeed, both ULMFiT and ELMo were a massive success, producing state-of-the-art results on numerous tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObcNBdbUq4j",
        "colab_type": "text"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLRBxqzUpN6",
        "colab_type": "text"
      },
      "source": [
        "BERT stands for “Bidirectional Encoder Representations from Transformers”. It is a neural network architecture that can model bidirectional contexts in text data using Transformer.\n",
        "\n",
        "Traditional language models are trained in a left-to-right fashion to predict the next word given a sequence of words. This has the limitation of not requiring the model to model bidirectional context. What does “bidirectional context” mean? For some words, their meaning might only become apparent when you look at both the left and right context simultaneously. The simultaneous part is important: models like ELMo train two separate models that each take the left and right context into account but do not train a model that uses both at the same time.\n",
        "\n",
        "BERT solves this problem by introducing a new task in the form of masked language modeling. The idea is simple: instead of predicting the next token in a sequence, BERT replaces random words in the input sentence with the special [MASK] token and attempts to predict what the original token was. In addition to this, BERT used the powerful Transformer architecture to incorporate information from the entire input sentence.\n",
        "\n",
        "Equipped with these two approaches, BERT achieved state-of-the-art performance across numerous tasks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTlnu4aVQiTi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "model_choice = \"en_pytt_bertbaseuncased_lg\" #@param [\"en_pytt_bertbaseuncased_lg\", \"en_pytt_xlnetbasecased_lg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq54PBavWdF0",
        "colab_type": "text"
      },
      "source": [
        "One important detail is that BERT uses wordpieces (e.g. playing -> play + ##ing)instead of words. This is effective in reducing the size of the vocabulary and increases the amount of data that is available for each word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCaAD1k7KiIi",
        "colab_type": "code",
        "outputId": "883b422d-ac8b-43bd-e330-2770be93840b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nlp = spacy.load(model_choice)\n",
        "doc = nlp(\"Here is some text to encode.\")\n",
        "assert doc.tensor.shape == (7, 768)  # Always has one row per token\n",
        "print(doc._.pytt_word_pieces_)  # String values of the wordpieces\n",
        "# The raw transformer output has one row per wordpiece.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'here', 'is', 'some', 'text', 'to', 'en', '##code', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFfXJFLSaMcd",
        "colab_type": "text"
      },
      "source": [
        "Here we can see that for the 10 word piece parts there is an individual encoding of size 768. Spacy provides a convenient utility to align the wordpieces back to the original words.  \n",
        "As the word **encode** has been split into its component parts - if we wanted to extract it's token representation as a single word we would need to pool together the 6th and 7th vector representations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A6p-Nn-aV5S",
        "colab_type": "code",
        "outputId": "7fcf665f-b66b-4c36-bb81-1a2d9c337a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(doc._.pytt_word_pieces)  # Wordpiece IDs (note: *not* spaCy's hash values!)\n",
        "print(doc._.pytt_alignment)  # Alignment between spaCy tokens and wordpieces"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 1012, 102]\n",
            "[[1], [2], [3], [4], [5], [6, 7], [8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ct-Sxk5XOiz",
        "colab_type": "text"
      },
      "source": [
        "We don't see any masked tokens as those are used during the training batches for the model to learn word representations. As we're using pre-trained models these masks are not part of the outputs. The special [CLS] and [SEP] tokens are still output as part of the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHdtIYVXcAc5",
        "colab_type": "text"
      },
      "source": [
        "BERT prepends a [CLS] token (short for “classification”) to the start of each sentence (this is essentially like a start-of-sentence token) and is used as an overall representation of the sentence in downstream tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFcmE1mQb-99",
        "colab_type": "code",
        "outputId": "19a735a3-7a24-4a47-f9f6-6ee2f89005fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"The {doc._.pytt_word_pieces_[0]} token embedding can be retrieved by getting the first embedding from the pytorch output - it's the same size as the other embeddings: {len(doc._.pytt_last_hidden_state[0])}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The [CLS] token embedding can be retrieved by getting the first embedding from the pytorch output - it's the same size as the other embeddings: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmXWLjrHe3Vu",
        "colab_type": "text"
      },
      "source": [
        "The last hidden state is the encoding value of the last hidden layer in the BERT architecture and can be retrieved using the *doc._.pytt_last_hidden_state* method.  \n",
        "Running the method on our document gives us the embedding for each wordpiece token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_dXJgxCW-s2",
        "colab_type": "code",
        "outputId": "cb46a251-6f5a-4e63-bb1a-597b0616940c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(doc._.pytt_last_hidden_state.shape)\n",
        "assert len(doc._.pytt_last_hidden_state) == len(doc._.pytt_word_pieces)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRQOGjDdfXnN",
        "colab_type": "text"
      },
      "source": [
        "If we wanted to retrieve every hidden layer's output the *doc._.pytt_all_hidden_states* accesses a tensor containing all layers of every token  \n",
        "** At time of writing this method doesn't yet work and is a known issue in the github **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7OaR5LUVhE3",
        "colab_type": "code",
        "outputId": "ba5a03df-1cf5-425f-93e5-a9432d9a19ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(doc._.pytt_all_hidden_states)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmskHTjTav8_",
        "colab_type": "text"
      },
      "source": [
        "While the [CLS] token is often used as a sentence representation in downstream tasks - it's also possible to sum the component embeddings for each word to get a sentence level vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPlyGbJPZ3g6",
        "colab_type": "code",
        "outputId": "5ac9ac10-287f-453e-92bf-3827334af3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"The sentence level representation retains the same embedding dimensions using a sum-pooled vector match : {len(doc.tensor.sum(axis=0))}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentence level representation retains the same embedding dimensions using a sum-pooled vector match : 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JivgE7RibkL_",
        "colab_type": "code",
        "outputId": "7eebe2f9-31a1-4aaa-9641-1c9cb8f8e4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "doc.tensor.sum(axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.92071831e+00, -2.27924675e-01,  9.30034518e-02, -1.93034962e-01,\n",
              "       -8.33929181e-01, -5.17823124e+00,  1.63885760e+00,  5.26988888e+00,\n",
              "       -5.49891591e-03,  4.23406363e-01,  4.84476984e-01, -2.48546958e+00,\n",
              "       -1.97492468e+00,  1.45040047e+00, -4.58841419e+00,  1.33792830e+00,\n",
              "       -3.63066268e+00,  2.52574968e+00,  3.23240161e-02,  1.73363376e+00,\n",
              "       -9.02754664e-01, -2.40544513e-01, -5.86369324e+00,  1.33724976e+00,\n",
              "        8.09447193e+00, -2.85938358e+00, -3.24457264e+00, -1.94612670e+00,\n",
              "       -7.56774235e+00, -2.41960573e+00,  5.64183593e-01,  8.24668646e-01,\n",
              "       -3.08341694e+00, -1.93161607e-01, -1.11684406e+00, -1.17629361e+00,\n",
              "        1.48193562e+00, -9.17339146e-01, -9.93975759e-01,  2.36142230e+00,\n",
              "       -7.09139729e+00, -2.71788001e+00,  2.19503140e+00,  7.31056631e-01,\n",
              "        4.54783440e+00, -3.48939514e+00,  4.75842571e+00, -1.59263515e+00,\n",
              "       -1.60763323e-01,  6.74959958e-01, -5.97016144e+00,  3.28443575e+00,\n",
              "       -9.77768183e-01,  3.29725933e+00,  3.51441240e+00,  5.23145294e+00,\n",
              "       -3.43903661e-01, -6.91251755e+00, -3.19126987e+00,  5.01669645e-01,\n",
              "        2.59982038e+00,  3.11265802e+00, -3.67475295e+00, -5.62059689e+00,\n",
              "        3.36200094e+00, -1.07927239e+00,  7.97904432e-02,  9.19599831e-01,\n",
              "       -1.08880625e+01, -2.93374801e+00, -5.01474476e+00, -6.28118801e+00,\n",
              "       -1.63564241e+00, -2.62475467e+00, -1.40201664e+00,  3.99704695e+00,\n",
              "       -4.39286709e+00,  1.46052027e+00, -3.97154140e+00, -3.93953419e+00,\n",
              "       -1.82605982e+00,  5.51324987e+00, -1.76549745e+00,  3.08551717e+00,\n",
              "        3.69003105e+00, -1.82436967e+00, -5.76437187e+00, -1.74665260e+00,\n",
              "       -2.72758007e+00,  3.77676773e+00, -1.90001416e+00, -6.11936390e-01,\n",
              "       -8.04168999e-01,  1.27664208e+00,  4.75507736e+00, -1.27682996e+00,\n",
              "       -2.08835459e+00,  3.65541482e+00, -1.37595069e+00,  3.29652715e+00,\n",
              "        1.77457166e+00, -4.22818375e+00,  2.71131396e+00, -1.74214149e+00,\n",
              "       -2.53007126e+00, -4.76854861e-01, -1.73535419e+00,  2.82738280e+00,\n",
              "        4.36472797e+00,  1.64266419e+00,  3.61045527e+00, -4.57057571e+00,\n",
              "        4.99968261e-01, -3.65650594e-01, -5.16320515e+00,  1.17697930e+00,\n",
              "        1.36396253e+00, -8.06679010e-01,  9.45729434e-01, -3.56211209e+00,\n",
              "       -5.69730341e-01,  3.40754330e-01,  1.31558001e+00,  9.38303375e+00,\n",
              "       -1.36814702e+00,  5.01520538e+00, -3.30154181e-01,  5.16698551e+00,\n",
              "        4.08692265e+00, -2.14737368e+00,  2.23410749e+00,  7.40507221e+00,\n",
              "        5.15285969e+00, -3.73267388e+00, -1.82323813e+00,  2.91274476e+00,\n",
              "        2.01573491e+00, -2.11040163e+00, -6.66435337e+00, -7.94025481e-01,\n",
              "        3.32578206e+00,  9.60492730e-01,  4.46967602e+00, -7.84203053e-01,\n",
              "        2.98428440e+00,  4.22360086e+00, -3.84640980e+00, -2.03774595e+00,\n",
              "        1.21445322e+00,  2.94687867e+00,  3.30819321e+00, -1.01059937e+00,\n",
              "       -1.16799784e+00,  1.75079072e+00, -3.45273972e+00,  2.16675496e+00,\n",
              "        1.43309939e+00,  2.96485376e+00,  8.53186607e-01,  2.52028847e+00,\n",
              "        6.67056084e+00,  5.67987442e-01, -2.00908470e+00,  1.22618425e+00,\n",
              "        1.43696904e+00,  4.50128436e-01, -2.59065300e-01,  3.18469191e+00,\n",
              "        4.85689104e-01, -3.01131606e-01, -5.25818062e+00,  6.31151915e-01,\n",
              "        5.85256338e+00, -9.92383718e-01, -3.33766484e+00,  3.44484663e+00,\n",
              "        8.97324800e-01,  4.47280502e+00,  4.21616888e+00, -6.77111864e-01,\n",
              "       -2.19733467e+01,  4.78255177e+00, -8.10009480e-01, -4.28565502e+00,\n",
              "        2.01696944e+00, -6.72775149e-01,  2.05348182e+00, -5.62805176e+00,\n",
              "       -3.75655603e+00, -1.49089098e-01, -3.80401516e+00, -9.81009603e-01,\n",
              "       -3.41021943e+00, -2.12788296e+00,  3.98419499e+00, -4.72480965e+00,\n",
              "       -6.03775859e-01, -6.23886943e-01, -1.64400458e+00,  1.76477516e+00,\n",
              "        8.71194243e-01,  7.23116398e-02,  1.45227802e+00,  9.07019079e-01,\n",
              "        1.18739963e+00, -1.27724600e+00,  1.68838561e+00, -6.35498285e-01,\n",
              "       -3.03215694e+00,  8.34060609e-02, -4.35079050e+00,  5.76508331e+00,\n",
              "       -7.38264799e-01, -2.30859876e+00,  2.72933936e+00, -6.22139335e-01,\n",
              "        1.57774913e+00, -5.86700141e-01, -4.68656445e+00, -2.83917487e-01,\n",
              "       -4.25481021e-01, -1.16330326e+00, -4.82808018e+00,  6.58038378e+00,\n",
              "       -5.21394730e-01,  7.15868092e+00, -1.16255760e-01,  2.75693798e+00,\n",
              "        7.19152737e+00,  1.36842883e+00, -1.07972980e-01, -2.15683460e+00,\n",
              "        5.03600121e+00,  2.53713083e+00, -3.45945549e+00, -1.62613761e+00,\n",
              "       -4.76050472e+00,  2.55304241e+00,  6.86458111e-01,  1.66915715e+00,\n",
              "        7.67743111e-01,  4.39762712e-01,  4.68080616e+00, -2.18304420e+00,\n",
              "       -2.40562010e+00, -7.36788809e-01, -1.42585242e+00, -1.53161079e-01,\n",
              "        4.67393970e+00, -4.05899048e+00,  3.22338867e+00, -5.95091438e+00,\n",
              "        1.09281433e+00, -6.79128838e+00, -1.00297570e+00,  9.39649701e-01,\n",
              "       -4.01409435e+00, -2.28144789e+00, -3.70267630e-01,  4.11445522e+00,\n",
              "        4.45992321e-01,  3.20690203e+00,  7.94265866e-01,  1.64253283e+00,\n",
              "       -9.78196621e+00, -5.83843994e+00,  2.10038114e+00,  1.30369675e+00,\n",
              "        2.97164822e+00,  1.36069012e+00, -1.37880528e+00, -3.32746005e+00,\n",
              "       -3.62387753e+00, -1.44693851e-01, -3.03085637e+00,  2.10597932e-01,\n",
              "        1.01521838e+00,  6.50712967e-01,  4.14906359e+00, -1.79582715e+00,\n",
              "       -6.19434714e-02,  3.83967543e+00, -3.16072798e+00,  5.18371677e+00,\n",
              "        2.39754915e-02, -3.46709967e+00, -5.23295760e-01, -1.92537940e+00,\n",
              "       -5.65473938e+00, -5.74062729e+00, -3.87220812e+00,  1.07801926e+00,\n",
              "       -3.01134920e+00, -1.54144239e+00,  4.95082092e+00,  3.45451999e+00,\n",
              "        4.81808853e+00,  9.03786659e-01, -1.46243262e+00, -5.36369228e+00,\n",
              "       -1.27302885e-01, -2.20462942e+00,  1.68899274e+00,  3.99255991e+00,\n",
              "       -8.79824638e+00,  2.80086040e+00, -3.55970478e+00, -4.74200964e+00,\n",
              "       -2.54924355e+01, -5.03116190e-01, -7.13526368e-01, -2.24845266e+00,\n",
              "        2.05855429e-01, -4.31477833e+00, -3.87100267e+00, -4.06010103e+00,\n",
              "       -3.07949710e+00, -4.44804251e-01, -7.24208117e-01, -4.32929802e+00,\n",
              "        3.58381176e+00,  4.28281069e+00,  3.99322772e+00,  4.50070858e+00,\n",
              "        1.79578733e+00,  7.59989262e-01, -3.98393822e+00,  4.50029469e+00,\n",
              "       -1.50201952e+00, -8.04409027e-01,  2.45064378e+00, -2.67230535e+00,\n",
              "        4.67668056e+00,  5.43653488e+00, -2.92271757e+00,  2.40065217e+00,\n",
              "       -4.34136295e+00, -3.18311858e+00, -2.40658104e-01, -1.35647821e+00,\n",
              "        2.24455428e+00, -1.87819791e+00,  1.98349011e+00,  7.63348639e-01,\n",
              "       -3.00229430e+00, -3.39595604e+00,  4.47662449e+00, -4.57597828e+00,\n",
              "       -1.79709089e+00,  1.65941453e+00,  1.62861204e+00, -7.68231487e+00,\n",
              "        5.51395416e+00, -4.64114761e+00, -1.20475125e+00, -2.04864836e+00,\n",
              "        1.26880690e-01,  7.43616962e+00, -2.26973462e+00,  4.67070222e-01,\n",
              "       -2.89214015e-01,  2.27774560e-01, -1.37904239e+00,  9.38034058e-03,\n",
              "        5.29815483e+00,  3.71559525e+00, -1.63568544e+00, -1.60885572e+00,\n",
              "        1.71080709e+00, -3.76137280e+00, -2.23598719e-01, -1.20720339e+00,\n",
              "       -1.99929309e+00, -2.61421657e+00, -2.35635710e+00, -1.54649389e+00,\n",
              "       -8.62488031e-01,  4.06910062e-01, -2.80636883e+00,  2.53939772e+00,\n",
              "       -6.64681959e+00, -8.14136314e+00, -1.70077455e+00,  1.32274055e+00,\n",
              "        6.01019263e-01, -5.97445488e-01,  3.53334761e+00, -3.38260174e+00,\n",
              "       -4.38304520e+00, -8.88005066e+00, -1.48362577e+00, -1.76523614e+00,\n",
              "       -1.82323027e+00, -2.56500149e+00,  1.15548754e+00, -6.34185123e+00,\n",
              "       -2.13857961e+00, -5.85910130e+00,  3.05508232e+00,  1.75359055e-01,\n",
              "       -1.13945711e+00,  9.95938063e-01, -1.99958086e-01, -7.43531227e-01,\n",
              "        7.00612211e+00, -8.49180603e+00,  3.81900764e+00,  1.79107204e-01,\n",
              "        4.44415808e-01, -1.92847550e+00,  4.12380695e+00, -5.89289427e-01,\n",
              "       -2.19030857e-01,  2.52700758e+00, -7.28505898e+00,  1.23545170e-01,\n",
              "        1.72034597e+00,  2.65499306e+00,  1.63682067e+00, -5.37367630e+00,\n",
              "        3.86439395e+00, -1.29181993e+00, -6.70695019e+00,  1.80035186e+00,\n",
              "        2.78196096e+00,  2.43799114e+00,  1.23938894e+00,  3.85081500e-01,\n",
              "        2.84131336e+00,  6.03916454e+00, -3.13152766e+00, -1.73647857e+00,\n",
              "       -4.84976053e+00, -2.25564408e+00,  2.01312518e+00, -5.52266717e-01,\n",
              "       -1.38388228e+00, -1.97307158e+00,  1.14222735e-01, -3.09220648e+00,\n",
              "       -1.21180654e-01,  2.49168110e+00,  3.42997718e+00, -2.25318742e+00,\n",
              "       -1.49089074e+00,  3.15642881e+00,  3.39825916e+00, -4.39026982e-01,\n",
              "       -5.32705367e-01,  4.06213856e+00, -2.66128612e+00, -1.19984615e+00,\n",
              "       -2.74344611e+00,  5.71743774e+00,  2.96957374e-01,  4.10658240e-01,\n",
              "        3.15381336e+00,  4.60193038e-01, -4.99184465e+00, -5.58882892e-01,\n",
              "       -2.79437125e-01, -2.41766596e+00,  1.83237267e+00, -3.67022157e+00,\n",
              "        2.81677032e+00, -3.31816792e+00,  1.86203718e+00, -4.21204567e+00,\n",
              "       -5.48508823e-01,  5.56994247e+00,  2.23243904e+00,  3.76683235e+00,\n",
              "        2.42359638e+00,  3.63441586e+00,  1.45802665e+00, -2.43719244e+00,\n",
              "       -3.22829819e+00,  1.85594380e+00, -2.95187593e+00,  1.74937010e-01,\n",
              "        1.93035054e+00,  5.05455852e-01,  1.96698332e+00,  8.43557262e+00,\n",
              "       -4.09043431e-01, -1.93461657e-01,  2.24150801e+00,  6.93349314e+00,\n",
              "        2.40417099e+00, -1.84758449e+00, -7.31837690e-01, -3.80455732e-01,\n",
              "       -1.02353239e+00,  5.75755692e+00, -1.13063312e+00,  1.62608588e+00,\n",
              "        4.85552818e-01, -2.63864994e-01, -8.48012924e+00,  2.26738906e+00,\n",
              "       -7.33784103e+00, -3.07929420e+00, -5.30258894e+00, -4.44760227e+00,\n",
              "        1.67742038e+00, -3.46928525e+00,  4.15996170e+00, -1.65668249e+00,\n",
              "        7.15942192e+00,  7.16603458e-01, -4.94963026e+00,  5.82944155e-01,\n",
              "       -8.12486231e-01, -1.01865137e+00,  2.34889293e+00,  1.45069170e+00,\n",
              "        2.25850970e-01,  5.44021606e-01,  1.77786422e+00, -5.28192616e+00,\n",
              "       -2.83672285e+00, -6.28319263e+00,  2.05787206e+00, -2.19111025e-01,\n",
              "        3.37394285e+00,  1.18093061e+00,  2.40402365e+00,  6.14415169e-01,\n",
              "       -5.82209110e+00,  2.69666409e+00,  2.95259833e+00,  3.82881856e+00,\n",
              "       -4.18458366e+00, -2.99740076e+00, -9.39688742e-01, -1.01641202e+00,\n",
              "       -7.58284760e+00,  1.73133719e+00,  1.11848569e+00, -3.14265871e+00,\n",
              "        6.22690618e-01,  2.47175145e+00,  4.71995497e+00, -2.02616358e+00,\n",
              "       -6.19953728e+00, -3.30824924e+00,  1.26933289e+00, -9.01718140e-01,\n",
              "       -1.13279831e+00,  3.61747116e-01,  3.43950796e+00, -3.52117014e+00,\n",
              "       -1.29642880e+00, -5.36547232e+00, -3.16120362e+00,  7.11368942e+00,\n",
              "       -4.27050447e+00,  2.67967010e+00,  3.84523094e-01,  5.31123817e-01,\n",
              "       -4.48134851e+00, -3.96366549e+00,  5.01558590e+00, -2.91963410e+00,\n",
              "       -5.72447395e+00,  2.85087109e+00, -2.61309910e+00,  6.24960279e+00,\n",
              "        7.97206354e+00, -1.35962510e+00,  1.48223615e+00,  5.85888672e+00,\n",
              "        4.51712513e+00,  1.34588754e+00,  4.85850334e-01,  1.95112300e+00,\n",
              "        8.54059339e-01, -3.33984375e+00, -2.32723475e+00, -3.55858803e-01,\n",
              "        9.69198942e-02,  1.63102150e+00, -2.99816060e+00, -3.62775993e+00,\n",
              "        4.54198456e+00, -8.32461643e+00,  1.05445993e+00, -3.89940333e+00,\n",
              "        1.64764369e+00,  4.72958374e+00,  4.70964551e-01, -1.54485762e-01,\n",
              "        7.84476221e-01, -1.36690474e+00, -3.84740090e+00,  3.69135118e+00,\n",
              "        1.19266224e+00, -1.16060531e+00, -1.33347845e+00,  6.16855907e+00,\n",
              "       -5.47436142e+00,  1.15192568e+00,  8.40952814e-01, -1.57534826e+00,\n",
              "        3.49223423e+00,  1.88070893e-01,  2.31602120e+00,  9.35021698e-01,\n",
              "        1.45431101e+00,  7.79714918e+00,  1.60556877e+00, -6.24087036e-01,\n",
              "        9.16775465e-01,  2.74838781e+00, -1.62136495e-01, -1.28081846e+00,\n",
              "        1.20537066e+00,  6.03951645e+00, -3.60219002e+00, -5.44166851e+00,\n",
              "        6.72917366e+00,  4.84254789e+00, -5.09027719e+00, -1.46149600e+00,\n",
              "        2.99294138e+00, -3.20804977e+00, -2.14681816e+00,  1.12418866e+00,\n",
              "        1.65189409e+00, -3.44275212e+00,  4.59517670e+00,  2.29476786e+00,\n",
              "       -4.72148895e+00,  4.74288511e+00, -4.67934752e+00, -2.69212866e+00,\n",
              "       -2.13195395e+00,  3.97079968e+00, -5.74040532e-01,  6.36711979e+00,\n",
              "       -2.25887418e-01,  5.09000969e+00, -4.67057753e+00, -5.17026806e+00,\n",
              "        3.34388232e+00,  3.48767614e+00,  2.38891363e+00, -9.85633731e-01,\n",
              "        5.20205677e-01,  2.45024228e+00,  3.08388662e+00,  9.57857132e-01,\n",
              "        1.79250813e+00, -9.61076498e-01,  3.54907483e-01,  6.27456665e-01,\n",
              "        4.32628202e+00,  4.32047033e+00,  1.85882974e+00,  4.27694035e+00,\n",
              "       -1.44910932e-01, -4.39180702e-01,  1.10263860e+00,  2.50258040e+00,\n",
              "        5.84168148e+00,  2.85441446e+00,  1.51387691e+00, -9.92009997e-01,\n",
              "        2.77427411e+00,  4.77442801e-01,  5.20341277e-01, -2.52174902e+00,\n",
              "       -2.03088045e+00,  5.20544529e+00,  3.94292068e+00,  1.33965909e-01,\n",
              "        1.29668903e+00, -5.88522077e-01, -2.46946478e+00,  1.67412663e+00,\n",
              "        1.10253739e+00, -8.55939507e-01, -2.50330353e+00,  4.47071934e+00,\n",
              "        3.95361471e+00,  2.88988590e-01, -5.58141041e+00, -4.46413374e+00,\n",
              "       -8.34658384e-01,  7.09407330e-02, -2.06993198e+00, -3.52671218e+00,\n",
              "       -3.26713920e+00, -7.13188696e+00,  3.91415358e-02,  7.86758363e-02,\n",
              "        1.63497448e+00, -2.19377828e+00, -1.67810172e-01, -4.41853285e+00,\n",
              "        1.18243814e+00, -5.08789301e+00,  7.43657887e-01, -3.90402126e+00,\n",
              "        1.23035419e+00,  4.53563786e+00,  5.81289673e+00,  9.82828200e-01,\n",
              "       -5.86771071e-01, -2.36716747e+00, -1.27675724e+00,  1.78632307e+00,\n",
              "        1.97299051e+00,  2.74908376e+00,  3.22986484e-01, -1.02588391e+00,\n",
              "       -1.22639072e+00, -6.47749519e+00,  3.34489226e+00,  5.11536884e+00,\n",
              "       -9.47832298e+00, -1.06561661e+00, -1.20595098e+00,  1.64683342e+00,\n",
              "        1.71935856e-01, -2.17813063e+00, -5.85146725e-01,  7.13856983e+00,\n",
              "       -2.48794198e+00, -1.10630250e+00,  5.10249710e+00,  6.53547668e+00,\n",
              "       -2.45196772e+00, -1.05995864e-01,  2.08180666e+00,  4.34676218e+00,\n",
              "       -1.11777556e+00, -3.23760319e+00,  7.07936764e+00,  3.64164686e+00,\n",
              "        2.88394547e+00,  2.39885354e+00, -1.05911613e-01, -1.53665304e+00,\n",
              "       -2.78753829e+00,  1.69380283e+00, -2.68149757e+00, -3.65553570e+00,\n",
              "       -2.19431400e+00,  2.75395870e-01,  2.97403717e+00, -2.24487782e+00,\n",
              "       -8.43623352e+00, -2.28678775e+00,  1.36759496e+00, -2.67910051e+00,\n",
              "       -1.85354590e+00, -3.25318193e+00,  2.69297838e+00,  2.53265905e+00,\n",
              "       -7.56149650e-01, -2.21078110e+00,  3.97919416e-01,  2.40517735e+00,\n",
              "        2.01296067e+00, -1.19751072e+00, -2.07586765e+00,  2.66453648e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZukNJrq1FP6",
        "colab_type": "text"
      },
      "source": [
        "## BERT's shortcomings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7qmyOpQ1Bwo",
        "colab_type": "text"
      },
      "source": [
        "BERT was already a revolutionary method with strong performance across multiple tasks, but it wasn’t without its flaws. XLNet pointed out two major problems with BERT.\n",
        "\n",
        "1. The [MASK] token used in training does not appear during fine-tuning\n",
        "\n",
        "BERT is trained to predict tokens replaced with the special [MASK] token. The problem is that the [MASK] token – which is at the center of training BERT – never appears when fine-tuning BERT on downstream tasks.\n",
        "\n",
        "This can cause a whole host of issues such as:\n",
        "\n",
        "What does BERT do for tokens that are not replaced with [MASK]?\n",
        "In most cases, BERT can simply copy non-masked tokens to the output. So would it really learn to produce meaningful representations for non-masked tokens?\n",
        "Of course, BERT still needs to accumulate information from all words in a sequence to denoise [MASK] tokens. But what happens if there are no [MASK] tokens in the input sentence?\n",
        "There are no clear answers to the above problems, but it’s clear that the [MASK] token is a source of train-test skew that can cause problems during fine-tuning. The authors of BERT were aware of this issue and tried to circumvent these problems by replacing some tokens with random real tokens during training instead of replacing them with the [MASK] token. However, this only constituted 10% of the noise. When only 15% of the tokens are noised to begin with, this only amounts to 1.5% of all the tokens, so is a lackluster solution.\n",
        "\n",
        "2. BERT generates predictions independently\n",
        "\n",
        "Another problem stems from the fact that BERT predicts masked tokens in parallel. Let’s illustrate with an example: Suppose we have the following sentence.\n",
        "\n",
        "*I went to [MASK] [MASK] and saw the [MASK] [MASK] [MASK].*\n",
        "\n",
        "One possible way to fill this out is\n",
        "\n",
        "*I went to New York and saw the Empire State building.*\n",
        "\n",
        "Another way is\n",
        "\n",
        "*I went to San Francisco and saw the Golden Gate bridge.*\n",
        "\n",
        "However, the sentence\n",
        "\n",
        "*I went to San Francisco and saw the Empire State building*\n",
        "\n",
        "is not valid. Despite this, BERT **predicts all masked positions in parallel, meaning that during training**, it does not learn to handle dependencies between predicting simultaneously masked tokens. In other words, it _does not learn dependencies between its own predictions_. Since BERT is not actually used to unmask tokens, this is not directly a problem. The reason this can be a problem is that this reduces the number of dependencies BERT learns at once, making the learning signal weaker than it could be.\n",
        "\n",
        "Note that neither of these problems is present in traditional language models. Language models have no [MASK] token and generate all words in a specified order so it learns dependencies between all the words in a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOLDrTLkm3jt",
        "colab_type": "text"
      },
      "source": [
        "## XL-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfC36c5Jm6-t",
        "colab_type": "text"
      },
      "source": [
        "The conceptual difference between BERT and XLNet. Transparent words are masked out so the model cannot rely on them. XLNet learns to predict the words in an arbitrary order but in an autoregressive, sequential manner (not necessarily left-to-right). BERT predicts all masked words simultaneously.\n",
        "\n",
        "\n",
        "XLNet does this by introducing a variant of language modeling called “permutation language modeling”. Permutation language models are trained to predict one token given preceding context like traditional language model, but instead of predicting the tokens in sequential order, it predicts tokens in some random order. To illustrate, let’s take the following sentence as an example:\n",
        "\n",
        "I like cats more than dogs.\n",
        "\n",
        "A traditional language model would predict the tokens in the order\n",
        "\n",
        "“I”, “like”, “cats”, “more”, “than”, “dogs”\n",
        "\n",
        "where each token uses all previous tokens as context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpEtawVV0WLb",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i2.wp.com/mlexplained.com/wp-content/uploads/2019/06/ezgif.com-gif-maker-1.gif?resize=447%2C170)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d8J5a100kzC",
        "colab_type": "text"
      },
      "source": [
        "In expectation, the model should learn to model the dependencies between all combinations of inputs in contrast to traditional language models that only learn dependencies in one direction.\n",
        "\n",
        "The difference between permutation language modeling and BERT is best illustrated below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BxkIUL70oP0",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i1.wp.com/mlexplained.com/wp-content/uploads/2019/06/Screen-Shot-2019-06-22-at-5.38.12-PM.png?resize=1024%2C567&ssl=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "d4r5-Lxd16Im",
        "colab": {}
      },
      "source": [
        "model_choice = \"en_pytt_xlnetbasecased_lg\" #@param [\"en_pytt_bertbaseuncased_lg\", \"en_pytt_xlnetbasecased_lg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KWaPB__T16I4"
      },
      "source": [
        "You can see that the XL-Net model also has the [SEP] and [CLS] tokens like the BERT model - these are in inverse positions however."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bWDTiDUo16I5",
        "outputId": "fad4dde5-1883-48f3-cc4f-0e5a16182a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nlp = spacy.load(model_choice)\n",
        "doc = nlp(\"Here is some text to encode.\")\n",
        "assert doc.tensor.shape == (7, 768)  # Always has one row per token\n",
        "print(doc._.pytt_word_pieces_)  # String values of the wordpieces\n",
        "# The raw transformer output has one row per wordpiece.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁Here', '▁is', '▁some', '▁text', '▁to', '▁encode', '.', '</s>', '<cls>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VlDyXzJe16JB"
      },
      "source": [
        "XL-Net doesn't use the the wordpiece model to perform tokenisation but instead uses sentencepiece which doesn't split up words into their component pieces - see encode is a single token/piece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yIt50u1a16JC",
        "outputId": "52e3d3ce-c576-4653-cba3-94b9c4ed24f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(doc._.pytt_word_pieces)  # Wordpiece IDs (note: *not* spaCy's hash values!)\n",
        "print(doc._.pytt_alignment)  # Alignment between spaCy tokens and wordpieces"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1960, 27, 106, 1758, 22, 26727, 9, 2, 3]\n",
            "[[0], [1], [2], [3], [4], [5], [6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoOFAmuL7qPx",
        "colab_type": "text"
      },
      "source": [
        "Spacy provides the same functionality that we previously saw with BERT: we can access the last hidden layer of each token by using the **._.pytt_last_hidden_state** method. It contains 9 embeddings of size 768 - One for each wordpiece (including the [SEP] and [CEP] special tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8i6UCwg7ph0",
        "colab_type": "code",
        "outputId": "d3ab9529-5ca1-4441-9b31-af5332ce9e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc._.pytt_last_hidden_state.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2dWl1eP8lAL",
        "colab_type": "code",
        "outputId": "3bd418e3-2b29-439b-f1e9-57b60ef95a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "doc._.pytt_last_hidden_state"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6708668 , -0.10368976, -1.0380412 , ..., -2.1029072 ,\n",
              "         0.80826056, -0.6334783 ],\n",
              "       [ 1.1516035 ,  2.223895  , -1.3279669 , ..., -3.9718854 ,\n",
              "        -0.04483375,  0.84301263],\n",
              "       [-0.2249024 ,  0.49099392, -0.02250613, ..., -2.9707425 ,\n",
              "        -0.2828139 , -0.15383056],\n",
              "       ...,\n",
              "       [ 1.5694005 , -0.27083898, -1.3036835 , ..., -2.2866685 ,\n",
              "         0.9364556 , -0.80197155],\n",
              "       [ 1.2542741 ,  1.8797662 , -0.839255  , ..., -0.8563609 ,\n",
              "         0.44199145,  0.13227461],\n",
              "       [ 1.2327385 ,  0.94765943, -0.7770286 , ..., -1.4631634 ,\n",
              "        -0.16925767, -0.14293624]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXiw3T6l8q24",
        "colab_type": "text"
      },
      "source": [
        "We can use a sum-pooled average to get the sentence embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxLzBmnq8nyA",
        "colab_type": "code",
        "outputId": "79acc814-7be4-4eea-d050-bbe4d2e89642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "doc.tensor.sum(axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.54540348e+00,  6.14545727e+00, -8.20588875e+00,  7.16287994e+00,\n",
              "       -6.73144197e+00, -3.27495265e+00, -8.50539398e+00,  4.96013045e-01,\n",
              "       -4.40655136e+00,  7.65885735e+00,  3.12696981e+00, -5.87493610e+00,\n",
              "        3.55438781e+00,  4.04397583e+00,  1.84187775e+01, -1.63962054e+00,\n",
              "       -2.47696817e-01,  1.96733177e+00, -1.38041649e+01, -5.40577841e+00,\n",
              "       -1.20556622e+01, -5.32064962e+00, -3.10930657e+00, -5.87842512e+00,\n",
              "       -1.68896818e+00,  1.59532518e+01,  8.84272575e+00,  1.57748318e+00,\n",
              "       -4.92697382e+00,  5.44802809e+00, -4.06198645e+00,  3.52588505e-01,\n",
              "        1.18580256e+01,  5.43454790e+00,  8.25824928e+00,  2.48180246e+00,\n",
              "        2.51639128e-01,  6.34586334e+00,  2.76604581e+00,  6.18543339e+00,\n",
              "       -1.66867328e+00,  3.10447216e+00, -3.45611858e+00,  1.15252209e+01,\n",
              "        5.62967730e+00,  2.62753785e-01, -1.33665428e+01,  1.26201363e+01,\n",
              "       -2.10457573e+01, -4.41241693e+00,  3.49115896e+00, -7.53876972e+00,\n",
              "        2.17938590e+00,  2.07181702e+01,  7.37940967e-01,  4.80575657e+00,\n",
              "        7.18117142e+00, -7.62489557e+00, -5.86534214e+00,  2.33813310e+00,\n",
              "       -5.83324814e+00,  3.18400908e+00, -7.87961149e+00,  1.32594311e+00,\n",
              "        1.02425790e+00,  1.84142697e+00,  2.52686977e+00,  4.97676611e-01,\n",
              "       -1.41959515e+01, -9.70551431e-01, -9.13812757e-01,  1.26375217e+01,\n",
              "        1.75682526e+01,  1.55109739e+00, -1.70482044e+01,  4.18044662e+00,\n",
              "       -9.07733917e+00, -4.94930744e+00, -1.23113241e+01,  2.79075670e+00,\n",
              "       -2.56870413e+00,  1.15817571e+00, -1.73572464e+01,  1.84035444e+00,\n",
              "        7.49924564e+00,  2.19150400e+00,  4.53231144e+00, -1.21118450e+01,\n",
              "        6.51602411e+00, -3.55670500e+00, -9.46063805e+00, -3.43480587e+00,\n",
              "        1.18259020e+01,  1.86262512e+00, -5.60451841e+00, -2.09330511e+00,\n",
              "       -1.91568851e+00,  8.61309338e+00,  4.01245356e+00, -3.40245867e+00,\n",
              "        2.58865428e+00, -1.05874577e+01, -2.66072416e+00,  1.95685625e-02,\n",
              "       -1.04097786e+01, -3.60332012e+00, -9.07781792e+00,  7.47756958e-02,\n",
              "       -7.93540621e+00, -2.58749223e+00,  9.13973618e+00, -3.67718387e+00,\n",
              "        1.38431950e+01,  3.77487993e+00, -8.27391243e+00,  1.51077986e-01,\n",
              "       -3.43776608e+00, -9.86147118e+00,  9.21159029e-01, -9.27761269e+00,\n",
              "       -1.78541489e+01,  2.29017973e+00, -6.81645679e+00, -3.53550792e+00,\n",
              "       -8.00233841e-01,  1.40148258e+01,  1.66478806e+01,  1.46304493e+01,\n",
              "       -7.56528139e-01, -3.55861092e+00, -7.71839428e+00,  4.76169014e+00,\n",
              "        3.09157109e+00,  5.82772255e+00,  1.49444675e+00,  5.32255554e+00,\n",
              "        1.68618355e+01, -2.71383071e+00, -3.50820804e+00,  3.71517420e+00,\n",
              "       -9.47370625e+00, -7.17384338e+00, -1.51248407e+00,  3.99468422e+00,\n",
              "       -4.06915522e+00, -5.97870541e+00, -2.16575623e+00, -5.49275017e+00,\n",
              "       -3.20536184e+00,  1.45252967e+00, -5.09772015e+00,  2.62826920e+00,\n",
              "       -4.15523529e+00,  9.17504692e+00,  1.53298891e+00,  1.63154781e+00,\n",
              "        5.58277512e+00,  5.97470379e+00,  4.77466965e+00,  1.11862507e+01,\n",
              "       -2.16691875e+00, -1.20404806e+01,  1.32618046e+01, -1.24512424e+01,\n",
              "        1.30979347e+01, -6.15285397e+00,  1.11504097e+01,  1.04748449e+01,\n",
              "        6.84392595e+00,  6.05401421e+00, -1.48637986e+00, -1.25712051e+01,\n",
              "       -4.99720860e+00,  5.69902086e+00,  1.68098557e+00,  1.13703079e+01,\n",
              "       -2.74438667e+00, -2.05476952e+00, -8.53209877e+00, -1.05177581e+00,\n",
              "       -6.79268217e+00, -8.54024601e+00,  1.40898776e+00, -7.65089417e+00,\n",
              "       -5.09186077e+00, -3.79541063e+00,  5.31839466e+00, -1.12764378e+01,\n",
              "        1.40101790e-01, -1.31827131e-01, -6.29628277e+00, -1.92972827e+00,\n",
              "       -9.44272804e+00,  4.78208590e+00,  2.93530583e+00,  1.13495874e+01,\n",
              "        7.05944538e+00, -7.84463882e+00,  5.74205494e+00, -4.17146397e+00,\n",
              "        8.55905151e+00,  1.39130974e+01, -1.44738579e+01,  3.15916538e+00,\n",
              "       -3.10819244e+00,  1.23794031e+01, -2.90377617e+00, -2.54514718e+00,\n",
              "        1.01465106e+00, -1.27225935e-01,  1.73776321e+01, -4.06883240e+01,\n",
              "       -1.09131107e+01,  2.72047186e+00, -7.89778614e+00,  5.92943430e+00,\n",
              "       -6.85119057e+00, -1.44382439e+01,  9.79045630e-02,  1.36714687e+01,\n",
              "        1.00745850e+01, -4.87051582e+00, -7.38609600e+00, -2.51925588e+00,\n",
              "       -1.48171749e+01,  1.61758041e+00,  1.26023798e+01, -2.41534138e+00,\n",
              "       -1.00081043e+01, -7.64220285e+00, -1.80487800e+00, -3.17979765e+00,\n",
              "       -1.08252358e+00,  1.13701868e+00,  3.54052258e+00, -1.14018130e+00,\n",
              "        5.34712791e+00,  6.70396757e+00, -4.70784664e+00,  8.26017952e+00,\n",
              "       -3.68054748e+00,  7.66113758e+00,  3.53082633e+00, -1.83780384e+00,\n",
              "        2.51101136e+00, -2.39769268e+00, -3.66956067e+00, -1.04638243e+01,\n",
              "       -9.52009869e+00, -1.81259785e+01, -7.69115448e-01, -5.47546959e+00,\n",
              "       -5.06263685e+00,  1.93903852e+00, -1.31504583e+01, -1.55400457e+01,\n",
              "        3.04211636e+01,  2.15774460e+01, -7.36393881e+00, -1.24435349e+01,\n",
              "       -1.37766914e+01,  2.68267536e+00, -6.25540829e+00, -1.74804363e+01,\n",
              "       -8.26964569e+00,  7.26474285e+00, -5.88090372e+00, -1.99080706e-02,\n",
              "       -7.47121906e+00, -7.64266253e+00, -9.25442886e+00,  7.83297205e+00,\n",
              "        3.86432743e+00,  2.32199693e+00,  2.91887379e+00,  2.48455310e+00,\n",
              "       -6.83890581e+00, -7.22707176e+00, -5.29902935e+00, -1.17049732e+01,\n",
              "        5.65756750e+00, -1.06596136e+01,  6.45069242e-01, -4.42212057e+00,\n",
              "       -1.58435125e+01, -1.92491302e+01, -2.60460067e+00, -1.26659751e+00,\n",
              "        9.25245404e-01, -1.00223265e+01, -1.26168656e+00, -1.17024970e+00,\n",
              "       -1.13478482e+00, -4.64329958e+00, -1.03011303e+01,  1.92231989e+00,\n",
              "        1.23829293e+00,  3.55023241e+00,  4.83882046e+00,  3.61381054e+00,\n",
              "       -3.76339006e+00,  5.16121244e+00,  1.61896586e-01,  1.62775764e+01,\n",
              "        2.18593693e+00, -4.54318666e+00, -2.03312111e+00, -8.04443932e+00,\n",
              "        3.80198145e+00, -1.19765205e+01, -1.94893554e-01,  7.64420033e+00,\n",
              "       -3.27559233e+00, -1.04843426e+00,  8.31423283e-01,  1.36792812e+01,\n",
              "       -6.02711725e+00, -7.25834942e+00, -1.86878414e+01, -8.79880619e+00,\n",
              "        1.26831408e+01, -2.84882283e+00, -5.79351187e-03, -4.06679487e+00,\n",
              "       -3.22521544e+00,  2.37899327e+00, -1.58531685e+01,  8.61405373e-01,\n",
              "       -1.22071028e+00,  7.33314943e+00, -6.78072205e+01, -5.05717707e+00,\n",
              "       -3.50547147e+00, -3.23203397e+00,  1.88248742e+00, -8.63735437e-01,\n",
              "        5.56329584e+00, -1.72728386e+01,  1.61050949e+01, -5.22856998e+00,\n",
              "        4.97379684e+00,  2.47863674e+00,  6.79842091e+00, -9.14173889e+00,\n",
              "        3.96650887e+00,  2.97718382e+00, -4.00924921e+00, -5.49730301e+00,\n",
              "        8.99622154e+00,  4.11235571e-01,  5.81605339e+00, -1.45069704e+01,\n",
              "        1.83047562e+01, -8.49791908e+00, -1.30175138e+00, -1.08572626e+00,\n",
              "        1.12505846e+01,  1.29574661e+01, -8.88730717e+00, -4.11637020e+00,\n",
              "       -1.55373983e+01, -7.59082985e+00, -4.73918390e+00, -3.53342915e+00,\n",
              "       -2.17338600e+01, -7.55748510e-01, -7.37249374e-01,  1.56543338e+00,\n",
              "       -4.68867254e+00,  5.96711159e+00, -9.22135162e+00,  7.82414627e+00,\n",
              "       -5.03213787e+00, -9.80644035e+00, -1.53864431e+01, -3.45207453e+00,\n",
              "        8.22717667e+00, -7.02456284e+00, -7.11820126e+00, -1.43972435e+01,\n",
              "       -5.78311443e-01,  3.80549955e+00, -2.82155633e+00,  7.59136868e+00,\n",
              "        4.47932816e+01,  4.05017018e-01, -4.90585995e+00,  2.47890562e-01,\n",
              "        2.08385444e+00,  6.61586189e+00,  3.74720526e+00,  5.76739264e+00,\n",
              "        2.64385390e+00, -3.74602270e+00, -5.94181776e-01,  2.45865107e+00,\n",
              "       -8.71531677e+00, -3.64312267e+00, -6.41585255e+00, -2.17270088e+00,\n",
              "       -8.76975894e-01, -6.76928520e+00, -2.64309430e+00,  5.61486149e+00,\n",
              "       -3.36911464e+00,  6.17531395e+00, -3.44486260e+00,  8.09612989e-01,\n",
              "        2.45221448e+00,  5.21094352e-02, -9.51943970e+00, -1.28846550e+01,\n",
              "       -3.99282532e+01,  1.50530565e+00, -6.98902273e+00, -4.47686863e+00,\n",
              "       -7.04452515e+00, -1.28358102e+00,  3.37201238e-01, -7.36926937e+00,\n",
              "        1.19712639e+01,  1.20312929e+00,  3.37993050e+00, -7.93999863e+00,\n",
              "        7.24095345e+00, -2.82407141e+00, -5.16763353e+00,  1.15519638e+01,\n",
              "        1.40725574e+01, -8.46840191e+00,  6.15252733e+00, -1.89282715e+00,\n",
              "       -1.18769360e+00,  5.14059734e+00,  4.80641842e+00, -9.06341362e+00,\n",
              "        1.10656643e+00,  6.77676582e+00,  7.52577782e-01,  2.61397505e+00,\n",
              "        2.41050124e+00,  1.87543297e+00, -4.08868265e+00, -2.10516572e+00,\n",
              "       -4.71804476e+00,  1.89726758e+00,  4.98342514e+00, -3.10660005e-01,\n",
              "        4.40495586e+00, -1.80702763e+01,  1.19784155e+01, -1.42018404e+01,\n",
              "       -6.90298080e+00, -1.41521187e+01, -1.72370167e+01,  6.40693521e+00,\n",
              "       -4.26155281e+00, -5.47550058e+00, -5.15474510e+00,  7.21917868e+00,\n",
              "       -1.52840114e+00,  4.73992872e+00, -5.41657686e+00,  9.78138208e-01,\n",
              "        3.21142077e+00,  8.66882706e+00,  3.06252360e+00, -1.44365349e+01,\n",
              "        5.70627832e+00, -1.06909924e+01,  1.06340055e+01, -8.94802856e+00,\n",
              "       -3.80212045e+00, -4.09626484e+00, -4.90387231e-01, -6.47169542e+00,\n",
              "        2.16815300e+01, -3.29209089e+00,  5.74207115e+00, -1.35171366e+01,\n",
              "       -2.47046590e+00,  8.73250675e+00, -3.49036503e+00,  7.56002140e+00,\n",
              "       -1.39715958e+00,  4.05525208e-01, -2.23135948e-02, -8.82358932e+00,\n",
              "       -2.70860529e+00,  8.16837692e+00,  2.66788745e+00,  9.16802597e+00,\n",
              "        1.16456962e+00, -1.50964298e+01,  3.08706021e+00, -1.23552537e+00,\n",
              "       -1.28270721e+01,  5.20087910e+00, -4.20492554e+00,  1.13921852e+01,\n",
              "       -9.43415260e+00, -3.17333698e+00,  1.44370437e+00, -1.51440649e+01,\n",
              "        1.29780316e+00,  2.49599123e+00, -6.93579102e+00,  5.06483841e+00,\n",
              "        1.81939197e+00,  1.01833496e+01, -1.13723385e+00,  1.35004826e+01,\n",
              "       -1.02722235e+01,  9.68494225e+00,  1.40575123e+01, -3.44029355e+00,\n",
              "        3.49075985e+00,  7.78439939e-01,  6.75318146e+00,  6.52120256e+00,\n",
              "        1.60899963e+01, -1.52670736e+01, -2.81746793e+00,  2.80579472e+00,\n",
              "        7.98017406e+00,  2.96365285e+00,  3.87613392e+00,  3.93181801e+00,\n",
              "       -1.55982676e+01,  1.56526566e+00,  5.42407322e+00,  7.78989601e+00,\n",
              "       -6.72256994e+00, -7.67190361e+00, -1.44473085e+01, -1.11384811e+01,\n",
              "        6.62606668e+00,  8.24894810e+00,  5.38156033e+00, -1.53614473e+01,\n",
              "        3.09968042e+00,  3.51552439e+00,  7.61095285e+00, -1.01111813e+01,\n",
              "        1.48954451e+00, -1.40048933e+00, -7.50186634e+00,  8.77443409e+00,\n",
              "       -6.95734739e-01, -5.29383183e+00, -5.12069988e+00,  5.54761791e+00,\n",
              "        8.06390667e+00, -4.39550018e+00,  7.45222807e+00,  9.67754650e+00,\n",
              "       -2.19047508e+01,  6.37497282e+00, -4.81994915e+00, -1.15164394e+01,\n",
              "       -1.04482002e+01,  2.26157999e+00, -1.96043243e+01,  4.90627468e-01,\n",
              "        7.03390169e+00, -1.76001763e+00,  2.67109799e+00,  1.79536552e+01,\n",
              "       -3.52225113e+00,  5.12819099e+00, -9.92946148e-01, -6.53379381e-01,\n",
              "        3.48075628e-01, -5.98268270e+00, -2.12224865e+01,  7.93457794e+00,\n",
              "       -4.04155731e+00,  6.90830994e+00,  4.34436798e-02,  1.50289288e+01,\n",
              "        5.00557232e+00, -2.47090530e+00,  1.02984867e+01, -1.52493477e+01,\n",
              "       -1.43388958e+01, -1.23998337e+01,  1.76662903e+01, -1.08798046e+01,\n",
              "       -3.29581165e+00,  9.33663082e+00,  1.25372696e+01,  8.27519417e+00,\n",
              "        5.32143402e+00,  3.63982534e+00,  2.11702919e+00,  1.05621586e+01,\n",
              "        2.38001871e+00, -5.88526249e-01,  1.41836309e+00, -1.21073236e+01,\n",
              "       -7.39941263e+00,  5.84236431e+00, -6.13852406e+00, -4.81138802e+00,\n",
              "        3.73921204e+00,  1.85531788e+01, -4.91556358e+00,  1.26504374e+01,\n",
              "       -9.53471279e+00, -4.09117508e+00,  7.24664021e+00, -1.05655308e+01,\n",
              "        1.17162466e+00,  3.45591116e+00,  1.90956950e+00,  5.11124277e+00,\n",
              "       -1.72114906e+01,  9.89711571e+00, -1.45480514e-01,  6.78569031e+00,\n",
              "        1.56613255e+01, -4.77892494e+00, -6.30766094e-01,  1.84189916e-01,\n",
              "       -7.36463118e+00, -7.22146130e+00, -4.17215919e+00, -6.68577385e+00,\n",
              "        1.34519110e+01,  1.24679794e+01,  2.35129395e+01, -1.05390425e+01,\n",
              "       -5.24619198e+00,  2.20405746e+00, -4.26720905e+00, -2.77851152e+00,\n",
              "       -5.83111668e+00, -2.10624409e+00,  5.88254404e+00, -1.23615990e+01,\n",
              "       -4.98295116e+00, -1.53337173e+01,  2.30713749e+00, -3.03583503e+00,\n",
              "       -5.65480280e+00,  1.32777977e+00,  5.49259329e+00,  9.73207474e+00,\n",
              "        2.96926975e+00,  2.66277766e+00, -1.17399101e+01, -7.41144753e+00,\n",
              "       -1.32620287e+01,  1.73972249e+00,  4.55858111e-01,  9.82085991e+00,\n",
              "       -2.20748854e+00, -2.49523759e+00, -9.34892941e+00, -3.86884499e+00,\n",
              "        7.59719276e+00, -1.77086496e+00,  7.04143286e+00, -2.18086338e+00,\n",
              "        2.40822363e+00, -9.04679680e+00, -1.89378023e+00,  1.15753564e+03,\n",
              "       -6.61448097e+00, -4.67105436e+00, -7.95427799e+00, -7.97103596e+00,\n",
              "       -5.23529291e+00, -4.43634844e+00, -6.42602146e-01,  9.57018757e+00,\n",
              "        1.81904066e+00, -4.70826244e+00,  1.23056469e+01, -8.56031895e+00,\n",
              "        7.14850426e-01,  7.29723024e+00,  2.30337811e+00, -1.36608016e+00,\n",
              "       -1.35616887e+00, -5.64974689e+00,  3.53882313e+00, -1.53492534e+00,\n",
              "       -4.39651775e+00, -5.71237659e+00,  8.29252911e+00,  9.39564133e+00,\n",
              "        1.77469749e+01,  7.40940475e+00,  9.56484258e-01,  3.32093000e+00,\n",
              "        1.15188541e+01,  1.24716735e+00,  2.90861130e+00, -7.80848265e-02,\n",
              "        1.69170494e+01,  8.76500416e+00,  6.74055386e+00,  3.76097727e+00,\n",
              "        2.04016876e+00,  1.30631628e+01,  7.93151951e+00, -3.89612007e+01,\n",
              "       -2.58302498e+00, -9.08487201e-01, -5.22164822e+00,  6.09981298e+00,\n",
              "       -3.60474563e+00, -1.35330677e+00,  5.17748690e+00,  8.82379436e+00,\n",
              "       -1.05876036e+01, -1.07682695e+01,  2.26196671e+00, -6.07166147e+00,\n",
              "        7.59686518e+00,  3.27163458e+00,  9.40657139e+00, -8.02354908e+00,\n",
              "       -1.22225599e+01, -3.93196368e+00,  1.40238972e+01,  7.99034500e+00,\n",
              "       -3.87105632e+00,  1.76731956e+00,  9.56603146e+00,  7.22861350e-01,\n",
              "        2.65737081e+00, -6.59098625e-01, -1.26959362e+01,  1.98412561e+00,\n",
              "        5.30540371e+00, -3.16870856e+00,  9.58971405e+00, -7.03756034e-01,\n",
              "       -6.16892052e+00, -1.22428284e+01, -4.61825275e+00, -1.00210724e+01,\n",
              "        6.18085766e+00,  2.88787723e+00,  1.27762737e+01, -8.42859268e+00,\n",
              "        6.50925112e+00, -9.73272085e-01, -6.88144970e+00,  1.27718294e+00,\n",
              "        6.45432711e+00,  4.51655006e+00,  1.05903301e+01, -7.01879311e+00,\n",
              "       -1.96834254e+00, -4.45168686e+00, -3.80172062e+00, -2.25229669e+00,\n",
              "       -7.02684927e+00,  1.20947304e+01,  1.81184697e+00, -1.59709454e+01,\n",
              "       -3.28952312e+00, -2.36045494e+01,  7.83413887e+00, -3.59186125e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdYETUiBcddG",
        "colab_type": "text"
      },
      "source": [
        "## SOTA powered Spacy Similarity "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "_zMjYNXSgabE",
        "colab": {}
      },
      "source": [
        "model_choice = \"en_pytt_bertbaseuncased_lg\" #@param [\"en_pytt_bertbaseuncased_lg\", \"en_pytt_xlnetbasecased_lg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ag2KReTdO2D",
        "colab_type": "text"
      },
      "source": [
        "As PyTorch transformers is integrated into the normal SpaCy pipeline and methods - we can use the **.similarity** method to compare vectors at both token level and at sentence level - see https://spacy.io/api/token#similarity. We can also access vectors directly using the **.vector** method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml1Mw8g0Segr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apple1 = nlp(\"Apple shares rose on the news.\")\n",
        "apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
        "apple3 = nlp(\"Apple pie is delicious.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ANGSPcpilt1",
        "colab_type": "text"
      },
      "source": [
        "At a token level - we can see that the word Apple has different embedding representations in each context and so the similarity of Apple & Apple in each context is different. The model correctly identifies the difference between the embedding representation of the company and the fruit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1NUD8QGihC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(apple1[0].similarity(apple2[0]))  # 0.73428553\n",
        "print(apple1[0].similarity(apple3[0]))  # 0.43365782"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5jzS0ji2aQ",
        "colab_type": "text"
      },
      "source": [
        "Similarly, this can be applied at a sentence level with the two Company related Apple sentence are more similar that the apple pie sentence is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xjw1bzrcDFM",
        "colab_type": "code",
        "outputId": "a1fdbfa7-3c49-4f5e-9f34-56040b2f0cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(apple1.similarity(apple2)) #0.69861203\n",
        "print(apple1.similarity(apple3)) #0.5404963"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.69861203\n",
            "0.5404965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "melSdrH5jVjl",
        "colab_type": "text"
      },
      "source": [
        "To understand what's going on under the hood, we can manually recreate the above similarity scores using numpy & scipy methods.\n",
        "First we perform a sum-pooled vector representation of each token to get a sentence embedding as we did above. Then we convert the cupy/chainer array to a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OZWp87dgRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1_embedding = cupy.asnumpy(apple1.tensor.sum(axis=0))\n",
        "a2_embedding = cupy.asnumpy(apple2.tensor.sum(axis=0))\n",
        "a3_embedding = cupy.asnumpy(apple3.tensor.sum(axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIUPTcPzkBkp",
        "colab_type": "text"
      },
      "source": [
        "Similarity is defined as **1 - cosine distance** between two arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXDNgXPdetVZ",
        "colab_type": "code",
        "outputId": "b8a59d51-8d4c-43e0-e09a-cf6574451ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Similarity between Sentence 1 and Sentence 2 is : {1 - distance.cosine(a1_embedding, a2_embedding)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between Sentence 1 and Sentence 2 is : 0.6986120343208313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDlin4s0gxJh",
        "colab_type": "code",
        "outputId": "7c9de59a-e447-4092-9593-a31e2039e259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Similarity between Sentence 1 and Sentence 3 is : {1 - distance.cosine(a1_embedding, a3_embedding)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between Sentence 1 and Sentence 3 is : 0.5404964685440063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCYP4vSdm_c9",
        "colab_type": "text"
      },
      "source": [
        "# Build a Sentiment Classifier using Spacy-PyTT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV1dMBeqG-Kx",
        "colab_type": "text"
      },
      "source": [
        "This is a notebook version of the example found in the SpaCy PyTorch Transformers Github repo: https://github.com/explosion/spacy-pytorch-transformers/blob/master/examples/train_textcat.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtY-e6I1jZdE",
        "colab_type": "text"
      },
      "source": [
        "**Restart the kernel prior to running this section as the memory allocation on the GPU from the previous sections will cause the code to error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvRUxThvGmvb",
        "colab_type": "text"
      },
      "source": [
        "Loading in additional libraries for this example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t_a1cU4E7ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import thinc\n",
        "import random\n",
        "import spacy\n",
        "import GPUtil\n",
        "import torch\n",
        "from spacy.util import minibatch\n",
        "from tqdm.auto import tqdm\n",
        "import unicodedata\n",
        "import wasabi\n",
        "import numpy\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGaOGrM2GQhS",
        "colab_type": "text"
      },
      "source": [
        "Ensuring GPU is in use: \n",
        "To run this example, ensure GPU MEM ~ 1% at start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYUnrNLBFRMU",
        "colab_type": "code",
        "outputId": "3b07e33c-6c2e-4cab-d725-4f88f91e5fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "spacy.util.fix_random_seed(0)\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "    print(\"GPU Usage\")\n",
        "    GPUtil.showUtilization()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  1% |  2% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUeI3d7NG8eW",
        "colab_type": "text"
      },
      "source": [
        "We'll use the IMDB movie database for sentiment analysis (https://ai.stanford.edu/~amaas/data/sentiment/). We've imported thinc which has the imdb dataset available as a build in method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVDVlegnD0st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _prepare_partition(text_label_tuples, *, preprocess=False):\n",
        "    texts, labels = zip(*text_label_tuples)\n",
        "    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n",
        "    return texts, cats\n",
        "\n",
        "def load_data(*, limit=0, dev_size=2000):\n",
        "    \"\"\"Load data from the IMDB dataset, splitting off a held-out set.\"\"\"\n",
        "    if limit != 0:\n",
        "        limit += dev_size\n",
        "    assert dev_size != 0\n",
        "    train_data, _ = thinc.extra.datasets.imdb(limit=limit)\n",
        "    assert len(train_data) > dev_size\n",
        "    random.shuffle(train_data)\n",
        "    dev_data = train_data[:dev_size]\n",
        "    train_data = train_data[dev_size:]\n",
        "    train_texts, train_labels = _prepare_partition(train_data, preprocess=False)\n",
        "    dev_texts, dev_labels = _prepare_partition(dev_data, preprocess=False)\n",
        "    return (train_texts, train_labels), (dev_texts, dev_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtsDDKy2Hjpe",
        "colab_type": "text"
      },
      "source": [
        "We can call the above functions to generate our training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvNA6LTEEEk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_texts, train_cats), (eval_texts, eval_cats) = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI4ZNqIrIGBS",
        "colab_type": "text"
      },
      "source": [
        "next we'll select the pytt model we want to use to load into spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "7QrsNYcaIENM",
        "colab": {}
      },
      "source": [
        "model_choice = \"en_pytt_xlnetbasecased_lg\" #@param [\"en_pytt_bertbaseuncased_lg\", \"en_pytt_xlnetbasecased_lg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfsM3mIBGDAc",
        "colab_type": "code",
        "outputId": "855e4c4b-8e9d-471f-cfe8-d3a4a54869a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nlp = spacy.load(model_choice)\n",
        "print(nlp.pipe_names)\n",
        "print(f\"Loaded model '{model_choice}'\")\n",
        "if model_choice == \"en_pytt_xlnetbasecased_lg\":\n",
        "  textcat = nlp.create_pipe(\n",
        "          \"pytt_textcat\", config={\"architecture\": \"softmax_class_vector\"}\n",
        "      )\n",
        "elif model_choice == \"en_pytt_bertbaseuncased_lg\":\n",
        "  textcat = nlp.create_pipe(\n",
        "          \"pytt_textcat\", config={\"architecture\": \"softmax_class_vector\"}\n",
        "      )\n",
        "else: \n",
        "  print(\"Choose a supported PyTT model\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sentencizer', 'pytt_wordpiecer', 'pytt_tok2vec']\n",
            "Loaded model 'en_pytt_xlnetbasecased_lg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8fhlT3WIjEU",
        "colab_type": "code",
        "outputId": "1da20a2f-faa1-4e10-8f42-d7d591df62bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " # add label to text classifier\n",
        "textcat.add_label(\"POSITIVE\")\n",
        "textcat.add_label(\"NEGATIVE\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNFWKkgtIut6",
        "colab_type": "code",
        "outputId": "dbd6a190-6538-4155-d9a4-7d70df2b1d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Labels:\", textcat.labels)\n",
        "nlp.add_pipe(textcat, last=True)\n",
        "print(f\"Using {len(train_texts)} training docs, {len(eval_texts)} evaluation\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels: ('POSITIVE', 'NEGATIVE')\n",
            "Using 23000 training docs, 2000 evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh-Xnh3JL12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total_words = sum(len(text.split()) for text in train_texts)\n",
        "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnMtV7pbOF-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iter=4\n",
        "n_texts=1000 #Changed number of texts to 75 to relieve pressue on GPU memory\n",
        "batch_size=8 #8 #batch-szie changed to 4 to relieve pressure on GPU memory\n",
        "learn_rate=2e-5\n",
        "max_wpb=1000\n",
        "pos_label=\"POSITIVE\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKg0EgDYjIcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclic_triangular_rate(min_lr, max_lr, period):\n",
        "    it = 1\n",
        "    while True:\n",
        "        # https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee\n",
        "        cycle = numpy.floor(1 + it / (2 * period))\n",
        "        x = numpy.abs(it / period - 2 * cycle + 1)\n",
        "        relative = max(0, 1 - x)\n",
        "        yield min_lr + (max_lr - min_lr) * relative\n",
        "        it += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LaQNbUqjKBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(nlp, texts, cats, pos_label):\n",
        "    tp = 0.0  # True positives\n",
        "    fp = 0.0  # False positives\n",
        "    fn = 0.0  # False negatives\n",
        "    tn = 0.0  # True negatives\n",
        "    total_words = sum(len(text.split()) for text in texts)\n",
        "    with tqdm(total=total_words, leave=False) as pbar:\n",
        "        for i, doc in enumerate(nlp.pipe(texts, batch_size=batch_size)):\n",
        "            gold = cats[i]\n",
        "            for label, score in doc.cats.items():\n",
        "                if label not in gold:\n",
        "                    continue\n",
        "                if label != pos_label:\n",
        "                    continue\n",
        "                if score >= 0.5 and gold[label] >= 0.5:\n",
        "                    tp += 1.0\n",
        "                elif score >= 0.5 and gold[label] < 0.5:\n",
        "                    fp += 1.0\n",
        "                elif score < 0.5 and gold[label] < 0.5:\n",
        "                    tn += 1\n",
        "                elif score < 0.5 and gold[label] >= 0.5:\n",
        "                    fn += 1\n",
        "            pbar.update(len(doc.text.split()))\n",
        "    precision = tp / (tp + fp + 1e-8)\n",
        "    recall = tp / (tp + fn + 1e-8)\n",
        "    if (precision + recall) == 0:\n",
        "        f_score = 0.0\n",
        "    else:\n",
        "        f_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yno_aYKmJHSN",
        "colab_type": "code",
        "outputId": "9079152e-681d-4ad9-e451-e0eddd107c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "416f4e2b196d43d995c7413aca85b8da",
            "44f260c98df848389a6ac8a10de52dad",
            "f28b0309f28d4349af4ea7c369b19c1b",
            "06099dfce5a346a1bc163e76be4e8bc3",
            "8dd7da4ae25045d199f869d6740e1e48",
            "0139ef592a3a462fa39074b431c391fd",
            "e4cdf6eac13146a49b7d737e5046a919",
            "c237e23650304025b83121c2b2fc87b3",
            "157a5af224c84b7bb328cc49f666ecd2",
            "50b461ef5a8048fdba68f433daf1cfd8",
            "2b4a3cd5a3f842a98f9f85ebf78f25e6",
            "5e35b807e5364f42a8cb910a399aad9e",
            "e98e9bfb6cb043518b5427816a3bd1b8",
            "c52339f287ac47818f72d17514a939b1",
            "8175ecd95b8b49a990369e3dbccd84a1",
            "1c1992b313b444ddaa16a91117227783",
            "2e502a7e6dd440d294611da709109594",
            "1e2dc3c58d614254be15e45a56b7091b",
            "341753933cea4c59a05d65dc799f53d6",
            "06cbc972d96c413c847ce6743a17741e",
            "e1e9de5345a84abbb4101f7d242c0868",
            "46522f60f3c54626a9d97f00e6e8f252",
            "e400271445b3423fb5c6e76d1ebc86d6",
            "394bc071560e4cde8a6696d05f1d7231",
            "474c8ae3da504fd8b21835268c0e9aa9",
            "3bbce3e295b64e45ac24a9eeb6024017",
            "5d24fa346469421d831379883e01b878",
            "b23424b0be824b53b4405f62f67d5f80",
            "6985545b7e7b42efab6bb4241b13ddaa",
            "1462da6392c94aed9153e037c2eec5df",
            "13aecc590050491e9758216d348bba86",
            "c15147003b2e41148f0a13d70b00ac80"
          ]
        }
      },
      "source": [
        "# Initialize the TextCategorizer, and create an optimizer.\n",
        "optimizer = nlp.resume_training()\n",
        "optimizer.alpha = 0.001\n",
        "optimizer.pytt_weight_decay = 0.005\n",
        "optimizer.L2 = 0.0\n",
        "learn_rates = cyclic_triangular_rate(\n",
        "    learn_rate / 3, learn_rate * 3, 2 * len(train_data) // batch_size\n",
        "    )\n",
        "print(\"Training the model...\")\n",
        "print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "\n",
        "pbar = tqdm(total=100, leave=False)\n",
        "results = []\n",
        "epoch = 0\n",
        "step = 0\n",
        "eval_every = 100\n",
        "patience = 3\n",
        "while True:\n",
        "    # Train and evaluate\n",
        "    losses = Counter()\n",
        "    random.shuffle(train_data)\n",
        "    batches = minibatch(train_data, size=batch_size)\n",
        "    for batch in batches:\n",
        "        optimizer.pytt_lr = next(learn_rates)\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(texts, annotations, sgd=optimizer, drop=0.1, losses=losses)\n",
        "        pbar.update(1)\n",
        "        if step and (step % eval_every) == 0:\n",
        "            pbar.close()\n",
        "            with nlp.use_params(optimizer.averages):\n",
        "                scores = evaluate(nlp, eval_texts, eval_cats, pos_label)\n",
        "            results.append((scores[\"textcat_f\"], step, epoch))\n",
        "            print(\n",
        "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(\n",
        "                    losses[\"pytt_textcat\"],\n",
        "                    scores[\"textcat_p\"],\n",
        "                    scores[\"textcat_r\"],\n",
        "                    scores[\"textcat_f\"],\n",
        "                )\n",
        "            )\n",
        "            pbar = tqdm(total=eval_every, leave=False)\n",
        "        step += 1\n",
        "    epoch += 1\n",
        "    print(f\"epoch {epoch}\")\n",
        "    # Stop if no improvement in HP.patience checkpoints\n",
        "    if results:\n",
        "        best_score, best_step, best_epoch = max(results)\n",
        "        print(f\"best score: {best_score}  best_step : {best_step}  best epoch : {best_epoch} \")\n",
        "        print(f\"break clause: {((step - best_step) // eval_every)}\")\n",
        "        if ((step - best_step) // eval_every) >= patience:\n",
        "            break\n",
        "\n",
        "    msg = wasabi.Printer()\n",
        "    table_widths = [2, 4, 6]\n",
        "    msg.info(f\"Best scoring checkpoints\")\n",
        "    msg.row([\"Epoch\", \"Step\", \"Score\"], widths=table_widths)\n",
        "    msg.row([\"-\" * width for width in table_widths])\n",
        "    for score, step, epoch in sorted(results, reverse=True)[:10]:\n",
        "        msg.row([epoch, step, \"%.2f\" % (score * 100)], widths=table_widths)\n",
        "\n",
        "    # Test the trained model\n",
        "    test_text = eval_texts[0]\n",
        "    doc = nlp(test_text)\n",
        "    print(test_text, doc.cats)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "416f4e2b196d43d995c7413aca85b8da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "157a5af224c84b7bb328cc49f666ecd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=477016), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r0.614\t0.825\t0.965\t0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e502a7e6dd440d294611da709109594",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "474c8ae3da504fd8b21835268c0e9aa9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=477016), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d859badcc455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_cats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"textcat_f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             print(\n",
            "\u001b[0;32m<ipython-input-16-47ce0cc6ac28>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(nlp, texts, cats, pos_label)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup, component_cfg)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, stream, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mActivations\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mActivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/model_registry.py\u001b[0m in \u001b[0;36msentence_fwd\u001b[0;34m(docs, drop)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0msents_per_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_per_doc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_per_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0macts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# To go from \"per sentence\" activations to \"per doc\" activations, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# just have to tell it where the sequences end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/model_registry.py\u001b[0m in \u001b[0;36mapply_model_to_batches\u001b[0;34m(inputs, drop)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRaggedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mlh_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/wrapper.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, inputs, drop)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# \"drop is None\" indicates prediction. It's one of the parts of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# Thinc's API I'm least happy with...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mmax_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swap_swa_sgd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_swa_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swap_swa_sgd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_swa_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, input_mask, attention_mask, mems, perm_mask, target_mapping, head_mask)\u001b[0m\n\u001b[1;32m    963\u001b[0m             outputs = layer_module(output_h, output_g, attn_mask_h=non_tgt_mask, attn_mask_g=attn_mask,\n\u001b[1;32m    964\u001b[0m                                    \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                                    head_mask=head_mask[i])\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[1;32m    577\u001b[0m         outputs = self.rel_attn(output_h, output_g, attn_mask_h, attn_mask_g,\n\u001b[1;32m    578\u001b[0m                                 \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                                 head_mask=head_mask)\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;31m# post processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0moutput_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mpost_attention\u001b[0;34m(self, h, attn_vec, residual)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;34m\"\"\"Post-attention processing.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# post-attention projection (back to `d_model`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ibnd,hnd->ibh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# the old interface of passing the operands as one list argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0moperands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ_cmqNzoqfD",
        "colab_type": "text"
      },
      "source": [
        "# Non original code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7OXmxrvowAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp.to_disk(\"xlnet_sentiment\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxQcUZKrc1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "2571704a-d85b-46ce-d064-ddc37533562e"
      },
      "source": [
        "!zip -r /content/xlnet_sentiment.zip /content/xlnet_sentiment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/xlnet_sentiment/ (stored 0%)\n",
            "  adding: content/xlnet_sentiment/pytt_wordpiecer/ (stored 0%)\n",
            "  adding: content/xlnet_sentiment/pytt_wordpiecer/cfg (deflated 11%)\n",
            "  adding: content/xlnet_sentiment/pytt_wordpiecer/model (deflated 49%)\n",
            "  adding: content/xlnet_sentiment/tokenizer (deflated 79%)\n",
            "  adding: content/xlnet_sentiment/meta.json (deflated 47%)\n",
            "  adding: content/xlnet_sentiment/vocab/ (stored 0%)\n",
            "  adding: content/xlnet_sentiment/vocab/vectors (deflated 45%)\n",
            "  adding: content/xlnet_sentiment/vocab/strings.json (deflated 67%)\n",
            "  adding: content/xlnet_sentiment/vocab/key2row (stored 0%)\n",
            "  adding: content/xlnet_sentiment/vocab/lexemes.bin (deflated 75%)\n",
            "  adding: content/xlnet_sentiment/pytt_textcat/ (stored 0%)\n",
            "  adding: content/xlnet_sentiment/pytt_textcat/cfg (deflated 23%)\n",
            "  adding: content/xlnet_sentiment/pytt_textcat/model (deflated 9%)\n",
            "  adding: content/xlnet_sentiment/pytt_tok2vec/ (stored 0%)\n",
            "  adding: content/xlnet_sentiment/pytt_tok2vec/cfg (deflated 54%)\n",
            "  adding: content/xlnet_sentiment/pytt_tok2vec/model (deflated 7%)\n",
            "  adding: content/xlnet_sentiment/sentencizer.json (deflated 24%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CvbeRusgoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9da5843-baec-40aa-b641-b51447824382"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff8s8zVqsnjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/xlnet_sentiment.zip /content/drive/My\\ Drive/spacy_models/xlnet_sentiment.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Qx2iVznLB-",
        "colab_type": "text"
      },
      "source": [
        "# More information & Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOcKO7T-TWLY",
        "colab_type": "text"
      },
      "source": [
        "**Sources & More information:**  \n",
        "*XL-Net explanation*  \n",
        "https://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/  \n",
        "Attention is all you need  \n",
        "https://arxiv.org/abs/1706.03762"
      ]
    }
  ]
}